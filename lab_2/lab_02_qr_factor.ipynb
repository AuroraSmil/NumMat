{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2:  Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../styles/tma4215.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "\n",
    "# Comment out next line and execute this cell to restore the default notebook style \n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a quick reminder of what we did in Lecture 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\DeclareMathOperator{\\Div}{div}\n",
    "\\DeclareMathOperator{\\Grad}{grad}\n",
    "\\DeclareMathOperator{\\Curl}{curl}\n",
    "\\DeclareMathOperator{\\Rot}{rot}\n",
    "\\DeclareMathOperator{\\ord}{ord}\n",
    "\\DeclareMathOperator{\\Kern}{ker}\n",
    "\\DeclareMathOperator{\\Image}{im}\n",
    "\\DeclareMathOperator{\\spann}{span}\n",
    "\\DeclareMathOperator{\\rank}{rank}\n",
    "\\DeclareMathOperator{\\dist}{dist}\n",
    "\\DeclareMathOperator{\\diam}{diam}\n",
    "\\DeclareMathOperator{\\sig}{sig}\n",
    "\\DeclareMathOperator{\\Id}{Id}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\VV}{\\mathbb{V}}\n",
    "\\newcommand{\\dGamma}{\\,\\mathrm{d} \\Gamma}\n",
    "\\newcommand{\\dGammah}{\\,\\mathrm{d} \\Gamma_h}\n",
    "\\newcommand{\\dx}{\\,\\mathrm{d}x}\n",
    "\\newcommand{\\dy}{\\,\\mathrm{d}y}\n",
    "\\newcommand{\\ds}{\\,\\mathrm{d}s}\n",
    "\\newcommand{\\dt}{\\,\\mathrm{d}t}\n",
    "\\newcommand{\\dS}{\\,\\mathrm{d}S}\n",
    "\\newcommand{\\dV}{\\,\\mathrm{d}V}\n",
    "\\newcommand{\\dX}{\\,\\mathrm{d}X}\n",
    "\\newcommand{\\dY}{\\,\\mathrm{d}Y}\n",
    "\\newcommand{\\dE}{\\,\\mathrm{d}E}\n",
    "\\newcommand{\\dK}{\\,\\mathrm{d}K}\n",
    "\\newcommand{\\dM}{\\,\\mathrm{d}M}\n",
    "\\newcommand{\\cd}{\\mathrm{cd}}\n",
    "\\newcommand{\\onehalf}{\\frac{1}{2}}\n",
    "\\newcommand{\\bfP}{\\boldsymbol P}\n",
    "\\newcommand{\\bfx}{\\boldsymbol x}\n",
    "\\newcommand{\\bfy}{\\boldsymbol y}\n",
    "\\newcommand{\\bfa}{\\boldsymbol a}\n",
    "\\newcommand{\\bfu}{\\boldsymbol u}\n",
    "\\newcommand{\\bfv}{\\boldsymbol v}\n",
    "\\newcommand{\\bfe}{\\boldsymbol e}\n",
    "\\newcommand{\\bfb}{\\boldsymbol b}\n",
    "\\newcommand{\\bfc}{\\boldsymbol c}\n",
    "\\newcommand{\\bfq}{\\boldsymbol q}\n",
    "\\newcommand{\\bfy}{\\boldsymbol y}\n",
    "\\newcommand{\\bff}{\\boldsymbol f}\n",
    "\\newcommand{\\bfp}{\\boldsymbol p}\n",
    "\\newcommand{\\bft}{\\boldsymbol t}\n",
    "\\newcommand{\\bfj}{\\boldsymbol j}\n",
    "\\newcommand{\\bfB}{\\boldsymbol B}\n",
    "\\newcommand{\\bfV}{\\boldsymbol V}\n",
    "\\newcommand{\\bfE}{\\boldsymbol E}\n",
    "\\newcommand{\\bfB}{\\boldsymbol B}\n",
    "\\newcommand{\\bfzero}{\\boldsymbol 0}\n",
    "$$\n",
    "## Reduced QR Factorization\n",
    "\n",
    "Let $A \\in \\RR^{m,n}$ and\n",
    "assume that we have a (full) $QR$ factorization such that\n",
    "\n",
    "\\begin{align}\n",
    "A = \n",
    "Q\n",
    "\\begin{pmatrix}\n",
    "\\widehat{R}\n",
    "\\\\\n",
    "0\n",
    "\\end{pmatrix} \\in \\RR^{m,n}\n",
    "\\end{align}\n",
    "where $Q = (\\bfq_1 | \\cdots | \\bfq_m) \\in O(m)$ is a orthogonal matrix, and \n",
    "$\\widehat{R} \\in \\RR^{n,n}$ is an upper triangular matrix.\n",
    "\n",
    "Then the __full__ $QR$ factorization can be transformed\n",
    "into a __reduced__ $QR$ factorizations of the form\n",
    "\\begin{align}\n",
    "A = \n",
    "\\widehat{Q}\n",
    "\\widehat{R}\n",
    " \\in \\RR^{m,n}\n",
    "\\end{align}\n",
    "with $\\widehat{Q} = (\\bfq_1 | \\cdots | \\bfq_n) \\in  \\RR^{m,n}$\n",
    "satisfying $\\widehat{Q}^T \\widehat{Q} = \\Id_n \\in \\RR^{n,n}$. Here $\\Id_n$ denotes\n",
    "the $n \\times n$ Identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from Lecture 7 that we can solve the least squares problem (l.s.p) by using the full QR factorization as follows:\n",
    "\n",
    "1) Define\n",
    "\\begin{align*}\n",
    "Q^T \\bfb \n",
    "= \\begin{pmatrix}\n",
    "\\bfb_1\n",
    "\\\\\n",
    "\\bfb_2\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "with $\\bfb_1 \\in \\RR^n$ and $\\bfb_2 \\in \\RR^{m-n}$.\n",
    "\n",
    "2) Solve \n",
    "$$\n",
    "\\widehat{R} \\bfx = \\bfb_1\n",
    "$$\n",
    "\n",
    "Note that $\\bfb_1 = \\widehat{Q}^T \\bfb$ so\n",
    "to solve the l.s.p you only need to compute the __reduced__ $QR$ factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gram-Schmidt Orthogonalization\n",
    "\n",
    "\n",
    "We quickly review the Gram-Schmidt orthogonalization method and show that\n",
    "it in fact can be used to compute the reduced $QR$ factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\{\\bfa_1,\\ldots,\\bfa_n\\} \\subset \\RR^m$ $n$ linear independent\n",
    "vectors in $\\RR^m$. The Gram-Schmidt orthogonalization process\n",
    "allows to orthogonalizes that set, that means, we can construct\n",
    "a set $\\{\\bfq_1, \\ldots, \\bfq_n \\}$ of orthogonal (orthonormal) vectors which have the same span as the original set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{alignat*}{3}\n",
    "\\bfy_1 &:= \\bfa_1, \\quad & &\\bfq_1 := \\dfrac{\\bfy_1}{\\|\\bfy_1\\|}\n",
    "\\\\\n",
    "\\bfy_2 &:= \\bfa_2 - \\langle \\bfq_1, \\bfa_2 \\rangle \\bfq_1, \\quad & &\\bfq_2 := \\dfrac{\\bfy_2}{\\|\\bfy_2\\|}\n",
    "\\\\\n",
    "\\ldots \n",
    "\\\\\n",
    "\\bfy_k &:= \\bfa_k - \\sum_{i=1}^{k-1} \\langle \\bfq_i, \\bfa_k \\rangle \\bfq_i, \\quad & &\\bfq_k := \\dfrac{\\bfy_k}{\\|\\bfy_k\\|}\n",
    "\\\\\n",
    "\\ldots\n",
    "\\\\\n",
    "\\bfy_n &:= \\bfa_n - \\sum_{i=1}^{n-1} \\langle \\bfq_i, \\bfa_n \\rangle \\bfq_i, \\quad & &\\bfq_n := \\dfrac{\\bfy_n}{\\|\\bfy_n\\|}\n",
    "\\end{alignat*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use that $\\bfa_i$ rewrite as\n",
    "\n",
    "\\begin{align*}\n",
    "\\bfa_1 &:= \\underbrace{\\| \\bfy_1\\|}_{r_{11}} \\bfq_1\n",
    "\\\\\n",
    "\\bfa_2 &:= \\underbrace{\\| \\bfy_2 \\|}_{r_{22}} \\bfq_2 \n",
    "+ \\underbrace{\\langle \\bfq_1, \\bfa_2 \\rangle}_{r_{12}} \\bfq_1\n",
    "\\\\\n",
    "\\ldots \n",
    "\\\\\n",
    "\\bfa_k &:= \\underbrace{\\| \\bfy_k \\|}_{r_{kk}} \\bfq_k + \\sum_{i=1}^{k-1} \\underbrace{\\langle \\bfq_i, \\bfa_k \\rangle}_{r_{ik}} \\bfq_i\n",
    "\\\\\n",
    "\\ldots\n",
    "\\\\\n",
    "\\bfa_n &:= \\underbrace{\\| \\bfy_n \\|}_{r_{nn}} \\bfq_n + \\sum_{i=1}^{n-1} \\underbrace{\\langle \\bfq_i, \\bfa_n \\rangle }_{r_{in}}\\bfq_i\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So turning back to a matrix $A \\in \\RR^{m,n}$ with $\\rank(A) = n$,\n",
    "we write $A$ in terms of it column vectors\n",
    "\\begin{align}\n",
    "A &= ( \\bfa_1 | \\bfa_2 | \\ldots | \\bfa_n ) \\quad \\text{and define}\n",
    "\\\\\n",
    "\\widehat{Q} &:= ( \\bfq_1 | \\bfq_2 | \\ldots | \\bfq_n ) \\in \\RR^{m,n}\n",
    "\\end{align}\n",
    "Then applying the Gram-Schmidt algorithms as above to the column vectors of $A$ leads  us the __reduced__ $QR$ factorization.\n",
    "\n",
    "\\begin{align*}\n",
    "( \\bfa_1 | \\bfa_2 | \\ldots | \\bfa_n )\n",
    "= \n",
    "( \\bfq_1 | \\bfq_2 | \\ldots | \\bfq_n )\n",
    "\\begin{pmatrix}\n",
    "r_{11} & r_{12} & \\cdots & r_{1n}\n",
    "\\\\\n",
    "& r_{22} & \\cdots & r_{2n}\n",
    "\\\\\n",
    "& & \\ddots & \\vdots\n",
    "\\\\\n",
    "& & & r_{nn}\n",
    "\\end{pmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Task 1\n",
    "\n",
    "Consider the Pseudocode\n",
    "\n",
    "### Algorithm 1\n",
    "\n",
    "Let $\\bfa_1, \\ldots, \\bfa_n \\in \\RR^{m}$ be linearly independent vectors.\n",
    "\n",
    "```\n",
    "for j = 1,2,...,n\n",
    "    y = a_j\n",
    "    for i = 1,2,...,j-1\n",
    "        r_ij = q_i^T a_j\n",
    "        y = y - r_ij q_i\n",
    "    end\n",
    "    r_jj = ||y||\n",
    "    q_j = y/r_jj\n",
    "end \n",
    "```\n",
    "\n",
    "Write a small Python function ```qr_factor``` to compute the reduced QR factorization for a given matrix $A$  by completing the following\n",
    "code (But read the hints below before you start!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def qr_factor(A):\n",
    "    Q = np.zeros(A.shape)\n",
    "    R = np.zeros((A.shape[1], A.shape[1]))\n",
    "    m, n = A.shape\n",
    "\n",
    "    for j in range(n):\n",
    "\n",
    "        y = A[:, j]\n",
    "        for i in range(j):\n",
    "            r_ij = Q[:, i].T @ y\n",
    "            R[i, j] = r_ij\n",
    "            y = y - r_ij * Q[:, i]\n",
    "\n",
    "        r_jj = norm(y)\n",
    "        q_j = y / r_jj\n",
    "\n",
    "        R[j, j] = r_jj\n",
    "        Q[:, j] = q_j\n",
    "    return (Q, R)\n",
    "\n",
    "\n",
    "A = np.array([[1, -4], [2, 3], [2, 2]])\n",
    "\n",
    "q, r = qr_factor(A)\n",
    "\n",
    "\n",
    "print(q @ r)\n",
    "\n",
    "print(q.T @ q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your program with the the matrix\n",
    "\\begin{align*}\n",
    "A =\n",
    "\\begin{pmatrix}\n",
    "1 & -4\n",
    "\\\\\n",
    "2 & 3\n",
    "\\\\\n",
    "2 & 2\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "Check whether the return matrices satisfy\n",
    "* $\\widehat{Q}^T \\widehat{Q} = \\Id $ (modulo machine precision errors!)\n",
    "* $\\widehat{Q} \\widehat{R} = A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints and useful code snippets\n",
    "\n",
    "Here are some hints derived from the received questions and observed\n",
    "pitfalls on Thursday. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When you define arrays make always sure that they are of _float type_ otherwise you might observe strange side effects if the elements are interpreted as _integers_ types.\n",
    "So either explicit define you numpy arrays using the keyword `dtype =  float` or write all (or at least __one__ of them) numbers as floating point, e.g. $1.0$ instead of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A1 = np.array([[1, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]])\n",
    "print(A1.dtype)\n",
    "\n",
    "A1 = np.array([[1, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]], dtype=float)\n",
    "print(A1.dtype)\n",
    "\n",
    "A1 = np.array([[1.0, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]])\n",
    "print(A1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As you also want to compute the $Q$ matrix, store the $q_i$ as column vectors\n",
    "  of this matrix.  \n",
    "* ```q_i^T a_j``` is just a the matrix way to write the scalar product \n",
    "  $\\langle \\bfq_i, \\bfa_j \\rangle$ \n",
    "  between the i-th column vector of $Q$ and j-th column vector of \n",
    "  $A$, see also the the code snippets below for how to compute\n",
    "  scalar products or arrays in Python.\n",
    "* Remember that indexing in Python starts with $0$. If you want do to a \n",
    "  loop over\n",
    "  some integers, use the ```range(n)``` function in Python, which\n",
    "  returns a list of integers $[0, 1, \\ldots, n-1]$ and \n",
    "  __excludes__ $n$. So in the outermost loop in Algorithm should\n",
    "  use a ```range(n)```. The range for the innermost loop over $j$ \n",
    "  is a bit \"tricky\" since don't shift the entire range as in the   \n",
    "  outermost loop! Instead it should be read as \"Start from the first index\n",
    "  (which in Python is 0) and run until one index below the outermost running index, \n",
    "  so the range for the innermost range should be `range(j)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reminder on useful operations on arrays and vectors in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A1 = np.array([[1, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]])\n",
    "A2 = np.array([[10, 20, 30],\n",
    "               [40, 50, 60],\n",
    "               [70, 80, 90]])\n",
    "A1*A2 # elementwise product\n",
    "\n",
    "# Creating two 4x3 matrices and one 3x4 matrix\n",
    "A1 = np.arange(12).reshape(4,3)\n",
    "A2 = 10*np.arange(12).reshape(4,3)\n",
    "A3 = 100*np.arange(12).reshape(3,4)\n",
    "\n",
    "\n",
    "print(\"A1 = \")\n",
    "print(A1)\n",
    "\n",
    "print(\"A2 = \")\n",
    "print(A2)\n",
    "\n",
    "print(\"A3 = \")\n",
    "print(A3)\n",
    "\n",
    "print(\"A1[1,2] = \")\n",
    "print(A1[1,2])\n",
    "\n",
    "# Similar effect, but  first version is preferred\n",
    "print(A1[1][2])\n",
    "\n",
    "# Get row nr 0 and nr 1. Remember that we start counting at 0.\n",
    "print(\"Extract Row 0 from A1\")\n",
    "print(A1[0,:])\n",
    "\n",
    "\n",
    "print(\"Extract Row 3 from A1\")\n",
    "print(A1[3,:])\n",
    "\n",
    "# Get 3rd column\n",
    "print(\"Extract Column 2 from A1\")\n",
    "print(A1[:,2])\n",
    "\n",
    "# If you want to compute the scalar product between, e.g. column vector 1 of A1\n",
    "# and column vector 2 of A2, you can simply do\n",
    "\n",
    "print(\"<a1_1, a2_2> =  \")\n",
    "\n",
    "A1[:,1]@A2[:,2]\n",
    "\n",
    "# If you want to compute the matrix product A1*A3\n",
    "# you can simply write \n",
    "print(\"A1*A3 =  \")\n",
    "A1@A3\n",
    "\n",
    "# Compute norms\n",
    "from numpy.linalg import norm\n",
    "# Compute 2-norm of the 0th colum vector of A1\n",
    "print(\"||a_1||_2 =\")\n",
    "print(norm(A1[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Task 2\n",
    "\n",
    "We consider the following __data fitting problem__: \n",
    "\n",
    "Let $\\{x_i\\}_{i=0}^{m-1}$ a set of $m$ equally space points\n",
    "of an interval $[a,b]$, that is, $x_0 = a$, $x_{m-1} = b$ \n",
    "and $|x_k - x_{k-1}| = (b-a)/(m-1) $. \n",
    "\n",
    "Let $n \\in \\NN$ some integer and \n",
    "assume we have the $m$ data points $y_i = P_{n-1}(x_i)$ for $i=0,\\ldots m-1$.\n",
    "where the function $P_{n-1}$ is a polynomial of order $n-1$ is a  is given\n",
    "\n",
    "$$\n",
    "P_{n-1}(x) = \\sum_{k=0}^{n-1} x^k\n",
    "$$\n",
    "\n",
    "Now we want to find the least-squares polynomial $\\widetilde{P}_{l}(x) = \\sum_{k=0}^l c_k x^k$  fitting the data $\\{(x_i, y_i)\\}_{i=0}^{m-1}$ in a least-squares sense.\n",
    "\n",
    "To do that we want to \"solve\" (as good as possible) the problem\n",
    "\\begin{align*}\n",
    "A =\n",
    "\\begin{pmatrix}\n",
    "1 & x_0 & x_0^2 & \\cdots & x_0^l\n",
    "\\\\\n",
    "1 & x_1 & x_1^2 & \\cdots & x_1^l\n",
    "\\\\\n",
    "\\vdots & \\vdots & \\vdots& & \\vdots\n",
    "\\\\\n",
    "1 & x_{m-1} & x_{m-1}^2 & \\cdots & x_{m-1}^l\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "c_0 \n",
    "\\\\\n",
    "c_1\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "c_l\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "y_0\n",
    "\\\\\n",
    "y_1\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "y_{m-1}\n",
    "\\end{pmatrix}\n",
    "= \\bfy\n",
    "\\end{align*}\n",
    "\n",
    "We can compute the coefficient vector $\\bfc$ by solving the l.s.p\n",
    "$\\min \\| A \\bfc - \\bfy \\|_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose $l = n-1$ so that we know by construction of the data points\n",
    "$y_i$ that the exact answer should be\n",
    "\\begin{align}\n",
    "\\bfc_{ex} = \n",
    "\\begin{pmatrix}\n",
    "1 , 1, \\ldots, 1 \n",
    "\\end{pmatrix}^T \\in \\RR^n\n",
    "\\end{align}\n",
    "\n",
    "Now proceed as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ Choose the interval end points $a = 2$, $b=4$, the number of data points to be  \n",
    "   $m = 11$. Now for polynomial orders $n-1 = 0, 1, 2, 3, 4, 5$,\n",
    "   compute $\\bfc_n \\in \\RR^n$ using the QR factorization you implemented above.\n",
    "   How does the expected solution compares with the computed one?\n",
    "   In particular, compute and tabulate $\\| \\bfc - \\bfc_{ex} \\|_2$ as \n",
    "   function of $n$. Pay attention to $n=5$ vs. $n=6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Define x data points using linspace\n",
    "x_data = np.linspace(2,4,num=11, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define polynomials you could use ```poly1d```, see [here](https://docs.scipy.org/doc/numpy-1.17.0/reference/generated/numpy.poly1d.html?highlight=poly1d#numpy.poly1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define y data points\n",
    "poly_grad = 5\n",
    "\n",
    "poly_coeff = ...\n",
    "poly = np.poly1d(poly_coeff)\n",
    "y_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define matrix A\n",
    "mono = lambda x, k: x**k\n",
    "A = np.array([mono(x_data,k) for k in range(0,poly_grad+1)], dtype=float)\n",
    "A = A.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the $QR$ factorization and computation of the proper rhs vector $\\bfb_1$ you \n",
    "need to solve $\\widehat{R} \\bfx = \\bfb_1$. To solve a system with a\n",
    "triangular matrix you can either use your code from the previous lab or\n",
    "the built-in function [solve_triangular](https://docs.scipy.org/doc/scipy-1.3.0/reference/generated/scipy.linalg.solve_triangular.html?highlight=solve_triangular#scipy.linalg.solve_triangular)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "   Your comments here: \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Next, you are asked to implemented a QR factorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qr_factor_modified(A):\n",
    "    ....  \n",
    "    return (Q,R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based the __modified Gram-Schmidt orthogonalization__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "Let $\\bfa_1, \\ldots, \\bfa_n \\in \\RR^{m}$ be linearly independent vectors.\n",
    "\n",
    "```\n",
    "for j = 1,2,...,n\n",
    "    y = a_j\n",
    "    for i = 1,2,...,j-1\n",
    "        r_ij = q_i^T y\n",
    "        y = y - r_ij q_i\n",
    "    end\n",
    "    r_jj = ||y||\n",
    "    q_j = y/r_jj\n",
    "end \n",
    "```\n",
    "\n",
    "from task 1\n",
    "\n",
    "\n",
    "```\n",
    "for j = 1,2,...,n\n",
    "    y = a_j\n",
    "    for i = 1,2,...,j-1\n",
    "        r_ij = q_i^T a_j\n",
    "        y = y - r_ij q_i\n",
    "    end\n",
    "    r_jj = ||y||\n",
    "    q_j = y/r_jj\n",
    "end \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot the difference to the standard Gram-Schmidt orthogonalization method?\n",
    "Explain, why this modfied method still a orthogonalization procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "   Your comments here: The difference is that when computing $r_{ij}$ one uses the ith colum directly from A instead of using the ith colum from the copymatrix Q. This means that the r_ij s are computed indepentently of each other. \n",
    "   \n",
    "   ## Hvorfor er dette lov??!! \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ The modified Gram-Schmidt process  is actually more stable with respect to rounding errors than the original/classical one. Test this claim and repeat the experiment from a) but now use the ```qr_factor_modified``` function based on the modified Gram-Schmidt method.\n",
    "How does the solution $\\bfc_n$ compares the one computed with the original Gram-Schmidt method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "   Your comments here: \n",
    "\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
